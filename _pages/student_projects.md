---
layout: page
permalink: /student_projects/
title: student projects
description: A list of proposals for student projects
nav: false
nav_order: 5
---

### Topological Localisation from Multi-Sensory Observations

This project will consist in improving the localisation accuracy of a state-of-the-art topological localisation and tracking algorithm that fuses observations from heterogeneous sensors to find the correct location of an entity moving in space. The current model is part of the LCAS navigation stack (<a class="title" href="https://github.com/LCAS/topological_navigation/">https://github.com/LCAS/topological_navigation/</a>) and based on particle filters. Possible improvement is the use of ML algorithms to optimise the parameters of the algorithm and to work optimally in different environments and with different observations.

*Related work*:
- Navigate-and-Seek: A Robotics Framework for People Localization in Agricultural Environments. <a class="title" href="https://ieeexplore.ieee.org/document/9477071">https://ieeexplore.ieee.org/document/9477071</a>
- APPLI: Adaptive Planner Parameter Learning From Interventions. <a class="title" href="https://ieeexplore.ieee.org/abstract/document/9561311">https://ieeexplore.ieee.org/abstract/document/9561311</a>

### Dataset of Human Visual Attention while Observing HRIs

In this project, you will work toward the creation of a dataset of videos of people interacting with a robot during human-robot interactions. The dataset will contain annotations of engagement and per-frame attention maps from gaze data of the coders who annotated the video. The first step of the project is collecting the videos from people interacting with <a href="https://www.lincolnmuseum.com/robot-at-lincoln-museum">Lindsey the tour guide robot</a>, after having obtained ethical approval. The second step is recruiting coders to annotate the video data for engagement while recording gaze informations. The creation of the dataset will enable training more accurate models for automatic detection of engagement.

*Related work*:
- Harmonizing the object recognition strategies of deep neural networks with humans. <a href="https://serre-lab.github.io/Harmonization/">https://serre-lab.github.io/Harmonization/</a>
- Are You Still With Me? Continuous Engagement Assessment From a Robot's Point of View. <a href="https://www.frontiersin.org/articles/10.3389/frobt.2020.00116/full">https://www.frontiersin.org/articles/10.3389/frobt.2020.00116/full</a>
  
### Generative AI for Face Anonymisation in Videos

Current approaches to anonymising people from publicly-recorded videos is using blurring effects that completely covers identifiable features. However, many real-world applications require the detection of facial features while ensuring anonymity, such as emotions or gaze detection in public spaces. Generative AI could solve this problem by changing face identities in videos while keeping key face features unchanged. In this project, the student will perform a lit review on Generative AI approaches for anonymisation and develop a model to perform such task based on publicly available video datasets. 
*Related work*:
- A generative adversarial network for face anonymization. <a href="https://link.springer.com/chapter/10.1007/978-3-030-33720-9_44">https://link.springer.com/chapter/10.1007/978-3-030-33720-9_44</a>

### Modelling Human Generated Trajectories for Robot Navigation Failures

In this project, you will develop a machine learning model that takes in input a series of robot navigation trajectories from human demonstrations and learns to reproduce these trajectories in the same spatial contexts.
*Related work*:
- Do Not Make the Same Mistakes Again and Again: Learning Local Recovery Policies for Navigation From Human Demonstrations. <a href="https://ieeexplore.ieee.org/document/8423079">https://ieeexplore.ieee.org/document/8423079</a>


### Happy to discuss any other project that may align with <a href="/research/">my research areas</a>.
